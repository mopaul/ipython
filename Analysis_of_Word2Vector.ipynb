{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from io import open\n",
      "from glob import glob\n",
      "from numpy import asarray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_file = '/home/mopaul/google_embs/200000.vocab'\n",
      "emb_file = '/home/mopaul/google_embs/200000.embs'\n",
      "words = open(word_file, 'r').read().split()\n",
      "embeddings = []\n",
      "for line in open(emb_file):\n",
      "    emb = line.strip().split(',')\n",
      "    embeddings.append([float(x) for x in emb[:-1]])\n",
      "embeddings = asarray(embeddings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import NearestNeighbors\n",
      "\n",
      "knn = NearestNeighbors(n_neighbors=20, algorithm='ball_tree')\n",
      "knn.fit(embeddings)\n",
      "\n",
      "word_id = {w:i for i, w in enumerate(words)}\n",
      "id_word = {i:w for i, w in enumerate(words)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_neighbors(word):\n",
      "    id_ = word_id[word]\n",
      "    point = embeddings[id_]\n",
      "    get_knn_point(point)\n",
      "\n",
      "def get_knn_point(point):\n",
      "    distances, indices = knn.kneighbors(point)\n",
      "    for i, (index, d) in enumerate(zip(indices[0], distances[0])):\n",
      "        print u'{: <3}{: <20}{: <10}'.format(i, id_word[index], d)\n",
      "        \n",
      "def get_knn_phrase(phrase):\n",
      "    accumulator = get_phrase_point(phrase)\n",
      "    get_knn_point(accumulator)\n",
      "    \n",
      "def get_phrase_point(phrase):\n",
      "    accumulator = 0\n",
      "    for word in phrase.strip().split():\n",
      "        accumulator += embeddings[word_id[word]]\n",
      "    return accumulator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nearest Neighbours of words\n",
      "============================\n",
      "\n",
      "This is a typical experiment where we sort the words by their Euclidean distance.\n",
      "\n",
      "**Observations**\n",
      "\n",
      "* apple is mainly a company in these embeddings.\n",
      "\n",
      "* book and books are close to each other. The space is partitioned by the meaning not by part of speech.\n",
      "\n",
      "* The neighbors of \"the\" are not quite expected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_neighbors('apple')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  apple               0.0       \n",
        "1  apples              2.42865850982\n",
        "2  peach               2.42869758428\n",
        "3  strawberry          2.5044329127\n",
        "4  fruit               2.6255139909\n",
        "5  cherry              2.6270862745\n",
        "6  plum                2.66443541094\n",
        "7  pear                2.67828432723\n",
        "8  N9ne                2.82859124361\n",
        "9  melon               2.83413056991\n",
        "10 apricot             2.84914754861\n",
        "11 orchard             2.86396304851\n",
        "12 strawberries        2.89913784829\n",
        "13 pomegranate         2.90991822912\n",
        "14 honey               2.91301399051\n",
        "15 M/V                 2.92770966807\n",
        "16 almond              2.92959455622\n",
        "17 IOI                 2.93336153365\n",
        "18 lindy               2.94552686292\n",
        "19 watermelon          2.94884806426\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_neighbors('january')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  january             0.0       \n",
        "1  Narodowy            3.07903454025\n",
        "2  inhumation          3.18325530348\n",
        "3  Vices               3.24745684688\n",
        "4  sum_i               3.41548951177\n",
        "5  NATS                3.49560576886\n",
        "6  container           3.54068460182\n",
        "7  cargo               3.59269211787\n",
        "8  hovercraft          3.67321142296\n",
        "9  Prerna              3.70240325049\n",
        "10 passenger           3.71700983879\n",
        "11 C\u00e6dwalla            3.73919956985\n",
        "12 liners              3.75104391613\n",
        "13 servicing           3.75197786131\n",
        "14 Maroondah           3.77559294482\n",
        "15 entombment          3.77888036097\n",
        "16 incarcerate         3.78888522468\n",
        "17 transport           3.80063255956\n",
        "18 Troubleshooters     3.81576322259\n",
        "19 catamaran           3.82380635931\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_neighbors('the')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  the                 0.0       \n",
        "1  and                 1.5520047056\n",
        "2  ,                   1.58389849607\n",
        "3  of                  1.61591678199\n",
        "4  chipping            1.67482052657\n",
        "5  .                   1.70351839072\n",
        "6  ths                 1.72501207064\n",
        "7  in                  1.73238571625\n",
        "8  both                1.75995116516\n",
        "9  thes                1.77575172111\n",
        "10 N.E.                1.82230819894\n",
        "11 </s>                1.84007029722\n",
        "12 this                1.86568680419\n",
        "13 hideouts            1.875003229\n",
        "14 worsted             1.90400276555\n",
        "15 The                 1.9082740899\n",
        "16 a                   1.90875500796\n",
        "17 another             1.92143910299\n",
        "18 deep-rooted         1.94808503482\n",
        "19 which               1.95067871864\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_neighbors('book')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  book                0.0       \n",
        "1  essay               2.21087375844\n",
        "2  books               2.26084038747\n",
        "3  novel               2.26773206254\n",
        "4  memoir              2.29590537285\n",
        "5  author              2.41650753334\n",
        "6  self-published      2.47418608259\n",
        "7  autobiography       2.47681636681\n",
        "8  published           2.49383749228\n",
        "9  Petlura             2.51494954954\n",
        "10 publication         2.51519745963\n",
        "11 biography           2.53166837779\n",
        "12 handbook            2.53685534677\n",
        "13 story               2.53745292992\n",
        "14 Author              2.55402167256\n",
        "15 editio              2.55848552962\n",
        "16 novella             2.6288863726\n",
        "17 preface             2.63160884688\n",
        "18 foreword            2.63770434014\n",
        "19 memoirs             2.64291475194\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nearest Neighbours of phrases\n",
      "==============================\n",
      "Here, I sum up the vectors of the phrase and then look at the nearest neighbours.\n",
      "\n",
      "**Observations**\n",
      "\n",
      "* The words that make up the phrase are still the closest to the phrase.\n",
      "* Notice that not all the words have the same influence, in the phrase \"second month of the year\", only {second, month, year} are close to the phrase it does not seem that {of, the} changed the phrase embeddings that much."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_knn_phrase(\"very good\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  good                2.48079731957\n",
        "1  very                2.61080941881\n",
        "2  quite               2.99760790665\n",
        "3  fairly              3.18643056922\n",
        "4  extremely           3.22758866296\n",
        "5  nice                3.23222735113\n",
        "6  decent              3.23852334932\n",
        "7  pretty              3.27547835392\n",
        "8  bad                 3.29122795965\n",
        "9  exceedingly         3.29772853778\n",
        "10 remarkably          3.29792885584\n",
        "11 too                 3.30967315354\n",
        "12 comparatively       3.35318192158\n",
        "13 incredibly          3.39175730733\n",
        "14 relatively          3.41440525032\n",
        "15 reasonably          3.43841218631\n",
        "16 poor                3.4444596482\n",
        "17 little              3.46667533234\n",
        "18 exceptionally       3.46956392699\n",
        "19 always              3.48927843547\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_knn_phrase(\"not good\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  good                2.4579714371\n",
        "1  not                 2.61080941881\n",
        "2  indeed              3.13023309587\n",
        "3  so                  3.16274087915\n",
        "4  decent              3.175116363\n",
        "5  bad                 3.18722947274\n",
        "6  reasonably          3.18959961862\n",
        "7  always              3.19123397533\n",
        "8  nevertheless        3.20733029326\n",
        "9  never               3.23033926735\n",
        "10 enough              3.2395143766\n",
        "11 whatever            3.25958481643\n",
        "12 truly               3.28269574449\n",
        "13 hardly              3.28475722834\n",
        "14 obviously           3.28659137704\n",
        "15 nonetheless         3.29013424423\n",
        "16 even                3.29143431164\n",
        "17 really              3.29561221251\n",
        "18 perfectly           3.29631227439\n",
        "19 anyway              3.32713476112\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_knn_phrase(\"not bad\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  bad                 2.4579714371\n",
        "1  not                 3.05225622494\n",
        "2  good                3.20414732307\n",
        "3  anyway              3.31044744037\n",
        "4  wrong               3.34070594323\n",
        "5  terrible            3.36727528215\n",
        "6  hurt                3.39525147501\n",
        "7  really              3.41319206266\n",
        "8  so                  3.42386198671\n",
        "9  indeed              3.43319365851\n",
        "10 nothing             3.44345019832\n",
        "11 unfortunately       3.446852745\n",
        "12 horrible            3.44930230116\n",
        "13 obviously           3.46233569517\n",
        "14 too                 3.47176609576\n",
        "15 anything            3.48288158581\n",
        "16 something           3.48472038879\n",
        "17 bothered            3.49482526123\n",
        "18 because             3.50427022901\n",
        "19 luck                3.51012007138\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_knn_phrase(\"extremely bad\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  bad                 2.87130775878\n",
        "1  extremely           3.05225622494\n",
        "2  incredibly          3.36043354416\n",
        "3  exceedingly         3.3823812823\n",
        "4  very                3.43220048011\n",
        "5  quite               3.48370340697\n",
        "6  excessively         3.49805003195\n",
        "7  too                 3.51249556159\n",
        "8  unpredictable       3.51459216166\n",
        "9  good                3.56825209125\n",
        "10 terribly            3.57918466852\n",
        "11 nasty               3.58499717101\n",
        "12 overly              3.63751723842\n",
        "13 poor                3.64912800066\n",
        "14 extraordinarily     3.66155056218\n",
        "15 notoriously         3.6630330386\n",
        "16 exceptionally       3.70711685008\n",
        "17 indifferent         3.71427706119\n",
        "18 dangerously         3.72211668493\n",
        "19 Flaccus             3.73207490447\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_knn_phrase(\"second month of the year\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  month               6.99828065235\n",
        "1  year                7.12010127299\n",
        "2  week                7.56836242914\n",
        "3  fortnight           7.66353050194\n",
        "4  day                 7.78968509393\n",
        "5  months              7.82251427477\n",
        "6  tenth               7.91677836374\n",
        "7  second              7.9267757225\n",
        "8  decade              7.92914133537\n",
        "9  days                7.95011188722\n",
        "10 third               7.97033867263\n",
        "11 twenty-fifth        8.01378097209\n",
        "12 fifth               8.02617591496\n",
        "13 Carrasquel          8.03045717961\n",
        "14 sixth               8.03230644115\n",
        "15 weeks               8.04274961892\n",
        "16 four-week           8.04820777121\n",
        "17 fourth              8.05333592642\n",
        "18 weekend             8.07495926378\n",
        "19 eighth              8.08769857718\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_knn_phrase(\"the month after january\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  january             5.8072527119\n",
        "1  month               5.83120490943\n",
        "2  fortnight           6.25364077567\n",
        "3  day                 6.26056677107\n",
        "4  year                6.27505362214\n",
        "5  days                6.31517550865\n",
        "6  months              6.32053195973\n",
        "7  after               6.32952180155\n",
        "8  week                6.34731624186\n",
        "9  30-day              6.38430233319\n",
        "10 seven-day           6.40462687089\n",
        "11 three-month         6.43022261586\n",
        "12 Drip                6.45087010396\n",
        "13 cruise              6.45370703042\n",
        "14 five-day            6.46153032003\n",
        "15 four-month          6.46450189214\n",
        "16 Tricolor            6.47344500562\n",
        "17 Databases           6.4860231256\n",
        "18 departing           6.48710200593\n",
        "19 mid-October         6.4871927003\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Decompose a sentence\n",
      "=====================\n",
      "\n",
      "Given a phrase a sum of the vectors of its own words, to reverse the procedure we have to solve the linear system\n",
      "```python\n",
      "Phrase = dot(Occurrence Matrix, Embeddings Matrix)\n",
      "Occurrence Matrix = dot(Phrase, Embedding Matrix Inverse)\n",
      "```\n",
      "Therefore, we need to calculate the psuedo inverse of embeddings matrix and look at the largest component of the solution.\n",
      "\n",
      "I am surprised it works really good! Of course, it is harder to decide at which component we should stop?! However, we can start building a partial solution and compare the sentence to the partial solution and stop we we start diverging from the sentence :).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy.linalg import pinv\n",
      "embeddings_inverse = pinv(embeddings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import dot\n",
      "\n",
      "def decompose(phrase):\n",
      "    words = dot(get_phrase_point(phrase), embeddings_inverse)\n",
      "    print '\\n'.join([u'{: <3}{: <20}{: <10}'.format(i, id_word[x], words[x]) for i, x in enumerate(reversed(words.argsort()[-15:]))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "decompose('not good')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  n\u2019t                 0.00122794896574\n",
        "1  n't                 0.00119002919838\n",
        "2  not                 0.000995519406453\n",
        "3  sfondo              0.000961246576128\n",
        "4  anymore             0.000829919390003\n",
        "5  hesitate            0.00080536050641\n",
        "6  good                0.000803557534412\n",
        "7  Huachuca            0.000781767597937\n",
        "8  0.6,0.7,0.8         0.000762623758042\n",
        "9  want                0.000758716321009\n",
        "10 disappoint          0.000758701907868\n",
        "11 bother              0.000752307600692\n",
        "12 Nor                 0.000750832196509\n",
        "13 really              0.000735449800762\n",
        "14 never               0.000733983075296\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "decompose('second month of the year')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  month               0.00288233873745\n",
        "1  year                0.0027097199186\n",
        "2  fortnight           0.00209130692818\n",
        "3  week                0.00203196355714\n",
        "4  months              0.00192616946758\n",
        "5  decade              0.00188430387503\n",
        "6  years               0.00186805396586\n",
        "7  semester            0.00180367427193\n",
        "8  Natacha             0.00177694369103\n",
        "9  weeks               0.00175388712506\n",
        "10 day                 0.00172105933706\n",
        "11 Pts                 0.00164942426985\n",
        "12 days                0.00159368741433\n",
        "13 Verband             0.00158997181852\n",
        "14 tenth               0.00153373450369\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "decompose('president of united states is Barrack Obama')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0  Barack              0.00266849890391\n",
        "1  Obama               0.00244582835177\n",
        "2  Mitt                0.00224625314128\n",
        "3  McCain              0.00194899671631\n",
        "4  President-elect     0.0018385440724\n",
        "5  presidential        0.00182977434145\n",
        "6  Biden               0.00181154978598\n",
        "7  Rodham              0.00180794023309\n",
        "8  H.W.                0.00179948901985\n",
        "9  electors            0.00177714111461\n",
        "10 Romney              0.00176054856565\n",
        "11 Mondale             0.00171804724845\n",
        "12 vice-presidential   0.00169828828729\n",
        "13 Hillary             0.00163183138868\n",
        "14 primaries           0.00160642545436\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Influence of Frequenct on Vector Norm\n",
      "======================================\n",
      "\n",
      "The results do not show anything obvious, again we do not know how these vectors were trained!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norms = (embeddings ** 2).sum(axis=1) ** 0.5\n",
      "indices = norms.argsort()\n",
      "print \"Largest vectors\"\n",
      "print '\\n'.join([u'{: <3}{: <20}{: <10}'.format(i, id_word[x], norms[x]) for i, x in enumerate(reversed(indices[-50:]))])\n",
      "\n",
      "print \"\\n\\nSmallest vectors\"\n",
      "print '\\n'.join([u'{: <3}{: <20}{: <10}'.format(i, id_word[x], norms[x]) for i, x in enumerate(indices[:50])])\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Largest vectors\n",
        "0  pyrams              14.5111286116\n",
        "1  PlotArea            12.5093777984\n",
        "2  T\u00e9a                 12.4036044908\n",
        "3  ScaleMinor          12.3146780391\n",
        "4  non-families        12.2244173572\n",
        "5  mollusk             12.1869616612\n",
        "6  :303                12.1504132495\n",
        "7  Pyramidellidae      12.0780635374\n",
        "8  positionNote        12.031945433\n",
        "9  x.y                 12.0075597606\n",
        "10 Avg                 11.9491314829\n",
        "11 BackgroundColors    11.924585769\n",
        "12 20,20               11.9020821546\n",
        "13 BarData             11.891273882\n",
        "14 darkgrey            11.754834132\n",
        "15 east-central        11.7464729191\n",
        "16 gridcolor           11.6794880742\n",
        "17 DateFormat          11.6043260796\n",
        "18 Geometridae         11.4928952468\n",
        "19 :455                11.4226147458\n",
        "20 :50                 11.3098586864\n",
        "21 micromollusk        11.2713943279\n",
        "22 TimeAxis            11.2558439723\n",
        "23 Gracillariidae      11.2549181845\n",
        "24 ISTAT               11.2388630148\n",
        "25 lightgrey           11.205670696\n",
        "26 Articulation        11.1862549841\n",
        "27 ScaleMajor          11.1731145523\n",
        "28 gastropod           11.0362413834\n",
        "29 1,1,1               10.9996493631\n",
        "30 :1000               10.9846176438\n",
        "31 0.6,0.7,0.8         10.9801449253\n",
        "32 sfondo              10.9528956275\n",
        "33 AlignBars           10.9389983737\n",
        "34 pitchersNote        10.8914898772\n",
        "35 :200                10.8167294065\n",
        "36 Tanith              10.7393937211\n",
        "37 Tortricidae         10.6805126012\n",
        "38 3e3e3               10.6680251576\n",
        "39 ImageSize           10.6523267523\n",
        "40 Kazhagam            10.6237150736\n",
        "41 Pos                 10.5854119915\n",
        "42 battersNote         10.5805254248\n",
        "43 LINEAR              10.5457028138\n",
        "44 Voivodeship         10.525267247\n",
        "45 Coleophoridae       10.5149028278\n",
        "46 :100                10.4955274275\n",
        "47 :30                 10.4679196063\n",
        "48 Artem               10.444290184\n",
        "49 Crambidae           10.3868736132\n",
        "\n",
        "\n",
        "Smallest vectors\n",
        "0  </s>                0.0160727555509\n",
        "1  Zhaoye              1.72321548863\n",
        "2  ,                   1.76351576716\n",
        "3  and                 1.77161571351\n",
        "4  the                 1.84039357412\n",
        "5  both                1.86717687093\n",
        "6  CBOT                1.88913730589\n",
        "7  chipping            1.91452835389\n",
        "8  Walternate          1.92206692478\n",
        "9  ths                 1.93993971416\n",
        "10 in                  1.96095026447\n",
        "11 Zev                 1.96138273614\n",
        "12 thes                1.96990112274\n",
        "13 .                   1.9711658306\n",
        "14 P3b                 1.98554743824\n",
        "15 while               1.99332899741\n",
        "16 likewise            2.00319881436\n",
        "17 deep-rooted         2.00512918411\n",
        "18 only                2.00718645991\n",
        "19 N.E.                2.01208584716\n",
        "20 latter              2.02688682638\n",
        "21 td                  2.04005559819\n",
        "22 ent                 2.04805516112\n",
        "23 actually            2.05784317908\n",
        "24 even                2.06164891196\n",
        "25 some                2.06195443003\n",
        "26 another             2.06258860145\n",
        "27 \u2014                   2.0681784482\n",
        "28 's                  2.06995792705\n",
        "29 Desportivo          2.07042371003\n",
        "30 of                  2.08163473746\n",
        "31 Paulos              2.09167623026\n",
        "32 aforementioned      2.0922886776\n",
        "33 called              2.09502993353\n",
        "34 thus                2.09614678896\n",
        "35 apparently          2.10263105129\n",
        "36 that                2.10360630082\n",
        "37 Mitty               2.10795967891\n",
        "38 ther                2.10995854488\n",
        "39 presumably          2.11846054512\n",
        "40 similarly           2.12477028855\n",
        "41 Zrenjanin           2.12618594397\n",
        "42 motorcycling        2.12667608842\n",
        "43 ot                  2.12677919\n",
        "44 nd                  2.13212786621\n",
        "45 a                   2.13494432196\n",
        "46 Ibert               2.13560746286\n",
        "47 as                  2.14429131982\n",
        "48 gravitationally     2.14915624177\n",
        "49 instead             2.15196085275\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}