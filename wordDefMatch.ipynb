{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import cPickle as pickle\n",
      "from io import open\n",
      "import numpy as np\n",
      "\n",
      "from nltk.corpus import wordnet as wn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x = pickle.load(open(\"/media/sf_D/wordEmbd/rami/polyglot-en.pkl\", \"rb\"))\n",
      "#word_emb = dict(zip(x[0], x[1]))\n",
      "\n",
      "word_file = '/home/mopaul/semantics/input/embeddings/lsa/en/100000.vocab'\n",
      "emb_file = '/home/mopaul/semantics/input/embeddings/lsa/en/100000.embs'\n",
      "words = open(word_file, 'r').read().split()\n",
      "embeddings = []\n",
      "for line in open(emb_file):\n",
      "    emb = line.strip().split(',')\n",
      "    embeddings.append([float(x) for x in emb[:-1]])\n",
      "embeddings = np.asarray(embeddings)\n",
      "word_emb = dict(zip(words, embeddings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_stop(sent, stopwords):\n",
      "    result = [word for word in sent.split() if word not in stopwords]\n",
      "    return \" \".join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords as stop\n",
      "\n",
      "stopwords = stop.words(\"english\")#[\"the\", \"is\", \"a\", \"an\", \"and\"]\n",
      "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
      "easy = [\"dog\", \"orange\"]\n",
      "words = [\"hell\" , \"healthy\"]\n",
      "defns = [remove_stop(wn.synsets(w)[0].definition, stopwords) if wn.synsets(w) else \"<UNK>\" for w in words ]\n",
      "word_defn = dict(zip(words, defns))\n",
      "print word_defn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'healthy': 'indicating good health body mind; free infirmity disease', 'hell': 'place pain turmoil;'}\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#composition\n",
      "default_emb = np.zeros(word_emb.get(\"cat\").shape)\n",
      "defn_emb = dict()\n",
      "for word in words:\n",
      "    defn_emb[word] = sum([word_emb.get(terms, default_emb) for terms in word_defn.get(word).split()])\n",
      "    #defn_emb[word] = [term for term in word_defn.get(word)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#distance matrix\n",
      "from nltk.cluster.util import cosine_distance\n",
      "\n",
      "N = len(words)\n",
      "dist_mat = np.zeros((N, N))\n",
      "for i, wr in enumerate(words):\n",
      "    wemb = word_emb.get(wr)\n",
      "    for j, wc in enumerate(words): \n",
      "        demb = defn_emb.get(wc)\n",
      "        dist_mat[i, j] = abs(cosine_distance(wemb, demb))\n",
      "        \n",
      "print dist_mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.8431319   0.95496262]\n",
        " [ 0.33484859  0.28306568]]\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#assign\n",
      "from munkres import Munkres \n",
      "assignment = [-1]*N\n",
      "\n",
      "m = Munkres()\n",
      "indexes = m.compute(dist_mat)\n",
      "for r, c in indexes:\n",
      "    assignment[r] = c\n",
      "\n",
      "print assignment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1]\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#predicted defn\n",
      "for widx, didx in enumerate(assignment):\n",
      "    word = words[widx]\n",
      "    correct_defn = word_defn.get(word)\n",
      "    assigned_defn = word_defn.get(words[didx])\n",
      "    print (word, correct_defn, assigned_defn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('hell', 'place pain turmoil;', 'place pain turmoil;')\n",
        "('healthy', 'indicating good health body mind; free infirmity disease', 'indicating good health body mind; free infirmity disease')\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}